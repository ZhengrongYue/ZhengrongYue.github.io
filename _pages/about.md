---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


‚ú® <font face="Cambria" color=RoyalBlue>Biograpgy</font> [<font face="Cambria" color=MidnightBlue>[CV]</font>](files/CV_ZhengrongYue.pdf)
======

<font face="Cambria">I am a Ph.D. student at Shanghai Jiao Tong University and Shanghai AI Lab. My advisors are </font>[<font face="Cambria">Yali Wang</font>](https://scholar.google.com/citations?hl=zh-CN&user=hD948dkAAAAJ)<font face="Cambria">. I received my B.S. degree in Computer Science and Technology from China University of Mining and Technology (Beijing) in 2024. Currently, I am a Research Intern at Shanghai AI Lab. I was fortunate to be involved in internship programs at Samsung and SIAT.</font>

<font face="Cambria">My research interests include:</font> 
- **<font face="Cambria">Unified Multimodal Understanding and Generation</font>**
- **<font face="Cambria">Video Understanding</font>**
- **<font face="Cambria">Video Generation</font>**
- **<font face="Cambria">Multimodal Agent</font>**

<font face="Cambria">Most of my work focuses on unified multimodal understanding and generation foundation models, covering model design, large-scale pretraining, dataset collection, and benchmark evaluation.</font>


üôè <font face="Cambria" color=Red>I'm actively pursuing intern opportunities in Multimodal Understanding and Generation. Feel free to reach out for potential collaborations.</font>

üìë <font face="Cambria" color=RoyalBlue>Publications</font>
======

- **<font face="Cambria" color=MidnightBlue>VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning</font>**
  <font face="Cambria">Zikang Wang*, Boyu Chen*, Zhengrong Yue*, Yi Wang, Yu Qiao, Limin Wang, Yali Wang .</font>
  <font face="Cambria">Arxiv, 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()

- **<font face="Cambria" color=MidnightBlue>VTTS: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception</font>**
  <font face="Cambria">Ziang Yan*, Yinan He*, Xinhao Li*, Zhengrong Yue*, Xiangyu Zeng, Yali Wang, Yu Qiao, Limin Wang, Yi Wang .</font>
  <font face="Cambria">Arxiv, 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()

- **<font face="Cambria" color=MidnightBlue>LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents</font>**
  <font face="Cambria">Boyu Chen*, Zhengrong Yue*, Siran Chen*, Zikang Wang*, Yang Liu, Peng Li, Yali Wang .</font>
  <font face="Cambria">Arxiv, 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()

- **<font face="Cambria" color=MidnightBlue>V-Stylist: Video Stylization via Collaboration and Reflection of MLLM Agents</font>**
  <font face="Cambria">Zhengrong Yue*, Shaobin Zhuang*, Kunchang Li*, Yanbo Ding*, Yali Wang.</font>
  <font face="Cambria">Computer Vision and Pattern Recognition (CVPR), 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()

- **<font face="Cambria" color=MidnightBlue>TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning</font>**
  <font face="Cambria">Xiangyu Zeng, Kunchang Li, Chenting Wang, Xinhao Li, Tianxiang Jiang, Ziang Yan, Songze Li, Yansong Shi, Zhengrong Yue, Yi Wang, Yali Wang, Yu Qiao, Limin Wang.</font>
  <font face="Cambria">International Conference on Learning Representations (ICLR), 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()

- **<font face="Cambria" color=MidnightBlue>Muses: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration</font>**
  <font face="Cambria">Yanbo Ding*, Shaobin Zhuang*, Kunchang Li*, Zhengrong Yue*, Yu Qiao, Yali Wang.</font>
  <font face="Cambria">Association for the Advancement of Artificial Intelligence (ECCV), 2025.</font>
  [<font face="Cambria">Paper</font>]() [<font face="Cambria">Code</font>]()


ü§µüèª <font face="Cambria" color=RoyalBlue>Internships</font>
======


- **<font face="Cambria">Shanghai Artificial Intelligence Laboratory, General Vision Lab (OpenGVLab)</font>**
  <font face="Cambria">July 2024</font>
  <font face="Cambria">Studied integrated video understanding and generation tasks within multimodal frameworks.</font>
  
- **Shenzhen Institute of Advanced Technology, Multimedia Lab (MMLAB)</font>**
  <font face="Cambria">November 2023</font>
  <font face="Cambria">Explored video style editing based on MLLM Agents.</font>
  
- **Samsung R&D Institute China-Beijing, Language Understanding Lab (LUL)</font>**
  <font face="Cambria">September 2023</font>
  <font face="Cambria">Developed a multilingual document question-answering large model for Galaxy Z-Fold smartphones based on RAG.</font>



üèÖ <font face="Cambria" color=RoyalBlue>Honors</font>
======

- <font face="Cambria">The 23td China Robotics and Artificial Intelligence Competition Intelligent Sorting Challenge (National No. 1) National First Prize(2022)</font>
- <font face="Cambria">The 17th National Undergraduate Smart Car Competition Xunfei Creative Group (National Top Four) National First Prize(2022)</font>
- <font face="Cambria">The 15th National College Student Energy Conservation and Emission Reduction Social Practice and Science and Technology Contest, National Third Prize(2022)</font>
- <font face="Cambria">The 15th China Undergraduate Computer Design Contest Provincial Third Prize(2022)</font>




ü§ù <font face="Cambria" color=RoyalBlue>Services</font>
======

- <font face="Cambria">Attend CVPR 2023 Beijing Workshop, 2023.06</font>
    

